---
title: "Mini Project Bayesian Statistics"
author: "S19323"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE)
```

```{r warning=FALSE}
# Data manipulation & visualization
library(tidyverse)     # For dplyr, ggplot2, tidyr, etc.
library(ggplot2)       # Visualization
#install.packages("bayesplot")
library(bayesplot)     # Bayesian diagnostic plots
#install.packages("ggmcmc")
library(ggmcmc)        # MCMC diagnostics plots
library(coda)          # MCMC objects analysis

# Bayesian regression & modeling
#install.packages("rstan")
library(rstan)         # Core Stan interface
#install.packages("rstanarm")
library(rstanarm)      # Easy Bayesian regression models (like lm/glm but Bayesian)
#install.packages("brms")
library(brms)          # Advanced Bayesian regression models using Stan
#install.packages("BayesFactor")
library(BayesFactor)   # Bayesian hypothesis testing

# Diagnostics & model checks
library(loo)           # Leave-one-out cross-validation & WAIC
library(posterior)     # Posterior analysis (works with rstan/brms)
#install.packages("tidybayes")
library(tidybayes)     # Tidy data + Bayesian posteriors
#install.packages("mcmcplots")
#library(mcmcplots)     # Trace plots, density plots for MCMC

# Optional (depending on your analysis)
#install.packages("MCMCpack")
library(MCMCpack)      # Additional Bayesian regression & sampling
#install.packages("invgamma")
library(invgamma)      # For prior specification in some models

```

```{r}
insurance <- read.csv("D:/bayesianMiniProject/insurance.csv")
head(insurance)
```

# Exploratory Data Analysis(EDA)

## Check for missing values

```{r}
colSums(is.na(insurance))
```

## Structure of the data set

```{r}
str(insurance)
```

There are 1407 observations and 7 variables in the data set. 3 of them are categorical variables and 4 of them are numerical variables.

## Summary of the 7 variables in the data set

```{r}
summary(insurance)
```

## Checking the levels of the categorical variables

```{r}
levels(as.factor(insurance$Gender))
levels(as.factor(insurance$Smoking_Status))
levels(as.factor(insurance$Region))
```

## Frequency tables for categorical variables

```{r}
table(insurance$Gender)
table(insurance$Smoking_Status)
table(insurance$Region)
```



```{r}
colnames(insurance) <- c("Age", "Gender", "BMI", "Num_of_children", "Is_smoker", "Region", "Charges")

head(insurance)
```

```{r}
library(ggplot2)
library(gridExtra)    
library(corrplot)  
library(dplyr)

# Scatterplots of continuous predictors vs Charges
p1 <- ggplot(insurance, aes(x = Age, y = Charges)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Charges vs Age")

p2 <- ggplot(insurance, aes(x = BMI, y = Charges)) +
  geom_point(alpha = 0.5, color = "darkgreen") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Charges vs BMI")

p3 <- ggplot(insurance, aes(x = Num_of_children, y = Charges)) +
  geom_jitter(alpha = 0.5, color = "purple", width = 0.2) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Charges vs Number of Children")

# Arrange scatterplots side by side
grid.arrange(p1, p2, p3, ncol = 3)


```

```{r}
# Gender vs Charges
b1 <- ggplot(insurance, aes(x = Gender, y = Charges, fill = Gender)) +
  geom_boxplot() +
  labs(title = "Charges by Gender") +
  theme(legend.position = "none")

# Smoker vs Charges
b2 <- ggplot(insurance, aes(x = Is_smoker, y = Charges, fill = Is_smoker)) +
  geom_boxplot() +
  labs(title = "Charges by Smoking Status") +
  theme(legend.position = "none")

# Region vs Charges
b3 <- ggplot(insurance, aes(x = Region, y = Charges, fill = Region)) +
  geom_boxplot() +
  labs(title = "Charges by Region") +
  theme(legend.position = "none")


# Arrange boxplots in 2x2 grid
grid.arrange(b1, b2, b3, ncol = 3)

```


## Histograms for numerical variables

```{r}
#install.packages("dplyr")
#install.packages('tidyr')
library(tidyr)
library(dplyr)
library(ggplot2)
# Separate numeric vs categorical
num_vars <- insurance[, sapply(insurance, is.numeric)]
cat_vars <- insurance[, sapply(insurance, is.character)]


# Reshape data
num_long <- insurance %>%
  pivot_longer(cols = where(is.numeric), names_to = "Variable", values_to = "Value")

# Plot
ggplot(num_long, aes(x = Value, fill = Variable)) +
  geom_histogram(bins = 30, alpha = 0.7, color="black") +
  facet_wrap(~Variable, scales = "free", ncol = 2) +
  theme_minimal() +
  theme(legend.position = "none")

```

```{r}
# Reshape data
cat_long <- insurance %>%
  pivot_longer(cols = where(is.character), names_to = "Variable", values_to = "Category")

ggplot(cat_long, aes(x = Category, fill = Category)) +
  geom_bar() +
  facet_wrap(~Variable, scales = "free", ncol = 2) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Correlation matrix (numeric variables only)

```{r}
cor(num_vars)

```

## Heatmap

```{r}
library(corrplot)
library(viridisLite)

corrplot(cor(num_vars), method="color", addCoef.col="black", tl.cex=0.8,
         col = viridis(200, option = "C"))
```

# Multiple linear regression

## Applying log transformation to Charges

```{r}
insurance$Log_Charges <- log(insurance$Charges)
head(insurance)
```

## Visualizing the effect of log transformation

```{r}
par(mfrow=c(1,2))
hist(insurance$Charges, main="Histogram of Charges", xlab="Charges", col="lightblue", border="black")
hist(insurance$Log_Charges, main="Histogram of Log(Charges)", xlab="Log(Charges)", col="lightgreen", border="black")
```

```{r}
shapiro.test(insurance$Log_Charges)
```

```{r}
# recommended Stan options for faster sampling
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

```{r}
glimpse(insurance)
summary(insurance$Charges)
summary(insurance$Log_Charges)
hist(insurance$Charges, breaks=60, main="Charges (raw)", xlab="Charges")
hist(insurance$Log_Charges, breaks=60, main="Log(Charges)", xlab="Log(Charges)")

```

## Prepare / encode predictors (factors, scaling)

```{r}
# Create a working copy
df2 <- insurance %>% 
  mutate(
    Gender = factor(Gender),
    Is_smoker = factor(Is_smoker),
    Region = factor(Region),
    Num_of_children  = factor(Num_of_children, levels = 0:5)  # treat child count as categorical
  )

df2
```

```{r}
# set reference to most frequent level (safe)
set_ref_to_mode <- function(x) {
  x <- droplevels(x) #drop unused levels
  ref <- names(sort(table(x), decreasing=TRUE))[1] # Sort table counts from largest to smallest, take name of largest
  relevel(x, ref = ref) # Sets that most frequent category as the reference level of the factor.
}
df2$Gender    <- set_ref_to_mode(df2$Gender)
df2$Is_smoker <- set_ref_to_mode(df2$Is_smoker)
df2$Region    <- set_ref_to_mode(df2$Region)
df2$Num_of_children <- set_ref_to_mode(df2$Num_of_children)
str(df2)
```

In regression models (including Bayesian regression with brms), categorical predictors are automatically converted into dummy variables. If we don’t set the reference level, R picks the first level alphabetically (e.g., "female" \< "male", so "female" becomes baseline).

Sometimes the alphabetical reference has very few observations - coefficients may be unstable or hard to interpret.

So this function ensures:

-   Most frequent category is chosen as baseline → stable comparisons.

-   Results are interpretable: coefficients tell how each less-common group differs from the “majority” group.

-   Avoids surprises (Picking "northwest" as Region reference just because "n" \< "s" alphabetically).

## Standardize continuous predictors (store means/sds for future prediction)
```{r}
#install.packages("purrr")   # if not already installed
library(dplyr)
library(purrr)

cont_vars <- c("Age","BMI")
mean_sd <- map_df(df2[cont_vars], ~ tibble(mean = mean(.x, na.rm=TRUE), sd = sd(.x, na.rm=TRUE)))

# create scaled columns
df2 <- df2 %>%
  mutate(
    Age_s      = (Age - mean_sd$mean[1]) / mean_sd$sd[1],
    BMI_s      = (BMI - mean_sd$mean[2]) / mean_sd$sd[2]
  )

df2

```



```{r}
library(brms)
# formula (using factor Num_of_children)
form <- bf(Log_Charges ~ Age_s + BMI_s + Num_of_children + Gender + Is_smoker + Region)

# Sensible priors (since Age_s/BMI_s are standardized)
priors <- c(
  prior(normal(0, 5), class = "Intercept"),
  prior(normal(0, 1), class = "b"),       # slope priors for predictors (std predictors -> ~N(0,1))
  prior(student_t(3, 0, 2.5), class = "sigma")  # weakly informative for residual sd
)

# fit model
fit_brms <- brm(
  formula = form,
  data = df2,
  prior = priors,
  family = gaussian(),      # if modelling Log_Charges
  chains = 4, iter = 4000, warmup = 1000, cores = 4,
  control = list(adapt_delta = 0.98, max_treedepth = 15),
  seed = 123
)

```
```{r}
# brms diagnostics
print(fit_brms)             # posterior mean, sd, Rhat, bulk/tail ESS
```


```{r}
bayes_R2(fit_brms)
```


```{r}
#  Convergence diagnostics
pp <- posterior_summary(fit_brms)
# Extracts posterior mean, sd, and credible intervals for all parameters
pp
```

```{r}
# Traceplots
plot(fit_brms)              
# Visualizes traceplots for all parameters + posterior densities
```
```{r}
#  Model fit
bayes_R2(fit_brms)         
# Bayesian R-squared, measures proportion of variance explained

loo_brms <- loo(fit_brms)  
# Approximate Leave-One-Out cross-validation
# For model comparison (smaller LOOIC = better predictive accuracy)
print(loo_brms)

```

```{r}
# brms pp check
pp_check(fit_brms, nsamples = 100)           # histogram / overlay
pp_check(fit_brms, type = "dens_overlay")

# check predictions aggregated by smoker status, for example
pp_check(fit_brms, group = "Is_smoker", type = "dens_overlay")

```



```{r}
library(brms)
form_raw <- bf(Charges ~ Age_s + BMI_s + Num_of_children + Gender + Is_smoker + Region)

priors_raw <- c(
  prior(normal(0, 5000), class = "Intercept"),   # broader intercept prior for large scale
  prior(normal(0, 1000), class = "b"),          # broader slopes for large scale
  prior(student_t(3, 0, 10000), class = "sigma") # very wide for residuals
)

fit_brms_raw <- brm(
  formula = form_raw,
  data = df2,
  prior = priors_raw,
  family = gaussian(),
  chains = 4, iter = 4000, warmup = 1000, cores = 4,
  control = list(adapt_delta = 0.98, max_treedepth = 15),
  seed = 123
)

```

```{r}
# brms diagnostics
print(fit_brms_raw)             # posterior mean, sd, Rhat, bulk/tail ESS
```

```{r}
bayes_R2(fit_brms_raw)
```


```{r}
# -----------------------------
# Convergence diagnostics
# -----------------------------
pp <- posterior_summary(fit_brms_raw)
# Extracts posterior mean, sd, and credible intervals for all parameters
pp
```

```{r}

# Traceplots
plot(fit_brms_raw)              
# Visualizes traceplots for all parameters + posterior densities

```


```{r}
#  Model fit
# -----------------------------
bayes_R2(fit_brms_raw)         
# Bayesian R-squared, measures proportion of variance explained

loo_brms_raw <- loo(fit_brms_raw)  
# Approximate Leave-One-Out cross-validation
# Useful for model comparison (smaller LOOIC = better predictive accuracy)
print(loo_brms_raw)

```



```{r}
# check Rhat and ESS
pp <- posterior_summary(fit_brms_raw)
# traceplots
plot(fit_brms_raw)              # traceplots + posterior distributions
mcmc_trace(as.array(fit_brms_raw), pars = c("b_Age_s", "b_BMI_s"))  # bayesplot helper

# more diagnostics
bayes_R2(fit_brms_raw)         # Bayesian R^2
loo_brms <- loo(fit_brms_raw)  # approximate LOO-CV
print(loo_brms)


```

```{r}
# brms pp check
pp_check(fit_brms_raw, nsamples = 100)           # histogram / overlay
pp_check(fit_brms_raw, type = "dens_overlay")

# check predictions aggregated by smoker status, for example
pp_check(fit_brms_raw, group = "Is_smoker", type = "dens_overlay")

```
























































































































